{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1: What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "Answer:\n",
        "Logistic Regression is a statistical method used for binary classification that models the probability that a given input belongs to a particular category. It uses the Sigmoid function to output values between 0 and 1.\n",
        "\n",
        "Unlike Linear Regression, which predicts continuous outcomes, Logistic Regression is used for categorical outcomes, typically 0 or 1. Also, Linear Regression uses a straight line to fit the data, while Logistic Regression maps the output through the logistic (sigmoid) function to ensure the predictions stay within [0, 1]."
      ],
      "metadata": {
        "id": "CI3IkvaPXM4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "### âœ… Explain the role of the Sigmoid function in Logistic Regression**\n",
        "\n",
        "The **Sigmoid function** plays a central role in Logistic Regression by converting the raw output of the linear model into a **probability** between 0 and 1. This makes it suitable for **binary classification problems**, where the goal is to predict whether an instance belongs to class 1 or class 0.\n",
        "\n",
        "#### ðŸ”¹ Formula:\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $z = w^T x + b$ (i.e., the linear combination of inputs and weights)\n",
        "* $\\sigma(z)$ is the predicted probability of the positive class\n",
        "\n",
        "#### ðŸ”¹ Role in Logistic Regression:\n",
        "\n",
        "* It ensures the model output is a **probability**, which can be interpreted easily.\n",
        "* Predictions are made by applying a **threshold** (e.g., 0.5):\n",
        "\n",
        "  * If $\\sigma(z) \\geq 0.5$, predict class 1\n",
        "  * If $\\sigma(z) < 0.5$, predict class 0\n",
        "* It makes the model **non-linear** despite using a linear equation, allowing it to classify points more effectively in a probabilistic way.\n",
        "\n",
        "#### ðŸ”¹ Summary:\n",
        "\n",
        "The Sigmoid function enables Logistic Regression to make **probabilistic predictions** and map any real-valued input into a bounded range $[0, 1]$, which is essential for binary classification.\n"
      ],
      "metadata": {
        "id": "k2fYwkCRXPge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "Answer:\n",
        "Regularization adds a penalty term to the loss function to prevent overfitting. In Logistic Regression, L1 (Lasso) or L2 (Ridge) regularization is often used.\n",
        "It discourages complex models by penalizing large coefficients, which leads to simpler and more generalizable models, especially useful when dealing with high-dimensional data.\n",
        "\n"
      ],
      "metadata": {
        "id": "I-seJROzXoSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4: What are some common evaluation metrics for classification models, and why are they important?\n",
        "Answer:\n",
        "Common metrics include:\n",
        "\n",
        "Accuracy â€“ Overall correctness.\n",
        "\n",
        "Precision â€“ True Positives / (True Positives + False Positives).\n",
        "\n",
        "Recall (Sensitivity) â€“ True Positives / (True Positives + False Negatives).\n",
        "\n",
        "F1 Score â€“ Harmonic mean of Precision and Recall.\n",
        "\n",
        "ROC-AUC â€“ Measures the model's ability to distinguish between classes.\n",
        "\n",
        "These metrics are critical to evaluate performance, especially on imbalanced datasets."
      ],
      "metadata": {
        "id": "5PS5efJkXuBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5: Python code to load CSV, split data, train logistic regression, and print accuracy\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Binary classification\n",
        "X, y = X[y != 2], y[y != 2]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict & evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8SGD7kyX0oT",
        "outputId": "995f4831-9135-41d1-862d-4b977947c48f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6: Train Logistic Regression with L2 regularization and print coefficients and accuracy\n",
        "model = LogisticRegression(penalty='l2', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Coefficients:\", model.coef_)\n",
        "print(\"Accuracy:\", model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npTDmJVnYC2Y",
        "outputId": "4d7d735d-b2a6-4280-9687-10e14a9f78bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [[-0.3753915  -1.39664105  2.15250857  0.96423532]]\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7: Multiclass classification using multi_class='ovr' and print classification report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Full multiclass\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1DycsdxYLyA",
        "outputId": "3954bdf1-d465-47e4-ad1b-27f1908af62e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8: Apply GridSearchCV to tune C and penalty hyperparameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjsZslwrYVQ0",
        "outputId": "389cc72f-5de3-42ed-97d7-ca3a6769397c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy: 0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9: Standardize features and compare accuracy with/without scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Without scaling\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Without Scaling Accuracy:\", model.score(X_test, y_test))\n",
        "\n",
        "# With scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_scaled = LogisticRegression()\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "print(\"With Scaling Accuracy:\", model_scaled.score(X_test_scaled, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFyakXhHYc4g",
        "outputId": "e393f318-51dd-4c5f-de80-369c10591436"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Without Scaling Accuracy: 1.0\n",
            "With Scaling Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10: Approach to building a Logistic Regression model for an imbalanced marketing dataset\n",
        "\n",
        "\n",
        "\n",
        "### **Answer:**\n",
        "\n",
        "To build a Logistic Regression model for predicting customer response in an e-commerce marketing campaign (with only **5%** responders), I would follow a systematic machine learning pipeline that addresses both data quality and class imbalance:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Data Handling**\n",
        "\n",
        "* **Clean the data**: Handle missing values, remove duplicates, and deal with outliers.\n",
        "* **Encode categorical variables**: Use one-hot encoding for nominal variables and label encoding if appropriate.\n",
        "* **Split the dataset**: Use `StratifiedTrainTestSplit` to preserve class proportions in both training and test sets.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Feature Scaling**\n",
        "\n",
        "* Apply **StandardScaler** to normalize numeric features so that all input features contribute equally to the model.\n",
        "* Scaling is important because Logistic Regression is sensitive to feature magnitudes.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Class Imbalance Handling**\n",
        "\n",
        "Given that only 5% of the data belongs to the positive class:\n",
        "\n",
        "* **Option 1: Resampling**\n",
        "\n",
        "  * Use **SMOTE** (Synthetic Minority Over-sampling Technique) to oversample the minority class.\n",
        "  * Alternatively, undersample the majority class (with caution to avoid information loss).\n",
        "* **Option 2: Class Weights**\n",
        "\n",
        "  * Use `class_weight='balanced'` in Logistic Regression to automatically adjust the loss function to handle imbalance.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Model Training and Hyperparameter Tuning**\n",
        "\n",
        "* Train a Logistic Regression model with regularization to prevent overfitting:\n",
        "\n",
        "  ```python\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  model = LogisticRegression(class_weight='balanced', penalty='l2', solver='liblinear')\n",
        "  model.fit(X_train, y_train)\n",
        "  ```\n",
        "* Tune hyperparameters using **GridSearchCV** to find the best combination of `C` (inverse of regularization strength) and `penalty` (L1 or L2).\n",
        "\n",
        "---\n",
        "\n",
        "### **5. Evaluation Metrics**\n",
        "\n",
        "Since the dataset is imbalanced, **accuracy is misleading**. Instead, evaluate the model using:\n",
        "\n",
        "* **Precision**: Proportion of predicted responders that are correct.\n",
        "* **Recall**: Ability to identify actual responders.\n",
        "* **F1-score**: Harmonic mean of precision and recall.\n",
        "* **ROC-AUC**: Indicates how well the model separates classes.\n",
        "* Use a **confusion matrix** to assess false positives and false negatives.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. Business Application**\n",
        "\n",
        "* Optimize for **recall** to capture as many responders as possible without overly sacrificing precision.\n",
        "* Adjust the classification threshold to align with the campaign budget and expected ROI.\n",
        "* Periodically retrain the model with updated data to reflect changing customer behavior.\n",
        "\n",
        "---\n",
        "\n",
        "### âœ… **Conclusion**\n",
        "\n",
        "A careful approach combining data preprocessing, resampling or weighted learning, feature scaling, hyperparameter tuning, and proper evaluation ensures that the Logistic Regression model performs effectively even on highly imbalanced marketing datasetsâ€”leading to better targeting, higher response rates, and improved business outcomes.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K7yhmABLYoOR"
      }
    }
  ]
}